# Folio: Atomic Notes Philosophy and Writing Principles

The atomic notes philosophy in Folio represents careful thinking about information granularity optimized for both embedding-based retrieval and LLM-based synthesis. The principles guiding note writing directly determine RAG system effectiveness.

The atomic principle means each note covers exactly one coherent topic. A note about React experience doesn't also discuss Python backend work. A note about the WhatNow contextual bandits implementation doesn't drift into discussing moh-ami's LLM integration. This focused scope ensures semantic embeddings capture a single clear meaning. When a query asks about React, the React note scores highly. When a query asks about Python, it doesn't - even though I use both. This precision prevents dilution where every note is somewhat relevant to everything, making nothing precisely relevant to anything.

The self-contained principle means each note includes enough context to make sense independently. A note about the Atlantis strategic pivot doesn't assume you've read the overview - it briefly explains what Atlantis is before discussing the pivot. A note about Nexus dashboard architecture mentions it's a work project at Nurtur before diving into technical details. This context inclusion means retrieved notes provide understanding without requiring reading other notes first. The LLM can synthesize answers from whatever notes are retrieved without needing to request additional context.

The size guidelines specify 200-500 tokens (approximately 150-375 words) per note. This range is large enough to develop ideas with examples and context but small enough to maintain focus on a single topic. Notes below 200 tokens often lack sufficient detail to be useful - they feel like bullet points rather than explanations. Notes above 500 tokens typically cover multiple topics that should be split into separate notes. The sweet spot around 300-400 tokens provides satisfying depth while maintaining atomic focus.

The first-person voice creates authenticity in generated answers. Notes are written as if I'm speaking directly to an interviewer: "I built Atlantis as a lake mapping system..." rather than "James built Atlantis as a lake mapping system..." This voice carries through to LLM-generated answers where the system prompt instructs answering as me in first person. The result feels like conversation with me rather than reading a biography about me. This authentic voice distinguishes Folio from generic portfolio presentations.

The natural language principle means writing conversationally rather than formally. Notes use contractions, occasionally start sentences with "And" or "But," include parenthetical asides, and generally sound like how I actually speak. This naturalness serves two purposes. First, it makes the notes more pleasant to read for anyone reviewing the knowledge base directly. Second, it provides examples of my voice for the LLM to learn from, improving answer authenticity. Stiff formal notes would generate stiff formal answers - conversational notes generate conversational answers.

The synonym inclusion enriches semantic meaning in embeddings. A note about leadership doesn't just use "leadership" - it uses "team dad," "mentoring," "bringing teams together," "consensus building," and "collaborative approach." These varied phrasings help the embedding capture the concept from multiple linguistic angles. Queries using any of these related terms will match the note through semantic similarity even if the exact query phrase isn't present. This synonym richness makes retrieval more robust to query phrasing variations.

The example inclusion provides concrete grounding for abstract concepts. A note about problem-solving doesn't just claim I'm good at problem-solving - it describes specific challenges from specific projects and how I solved them. These concrete examples help embeddings capture not just the concept but the context and application. They also give the LLM specific content to reference in answers, making responses detailed rather than vague generalities.

The duplicate information strategy deliberately repeats key information across notes when relevant. Multiple notes mention that Atlantis underwent a strategic pivot from underwater drone to surface boat mapping system because this pivot is important context for understanding several different aspects of the project. This redundancy ensures whichever notes get retrieved have necessary context. It contrasts with traditional writing where redundancy is edited out - in atomic notes, redundancy ensures self-containment.

The structure guidelines provide consistent note organization. Notes typically start with a concise overview sentence or two establishing what the note is about. The body develops the main points with explanations, examples, and details. The conclusion often connects to broader patterns or implications. This consistent structure helps both embeddings and LLM processing - embeddings capture that notes follow similar patterns, and LLMs can more reliably extract information from consistently structured text.

The writing process balances planning with iteration. Initial notes were outlined based on key topics to cover, then written in detail, reviewed for self-containment and scope, tested by running queries, and refined based on retrieval results. Some notes that initially covered too much got split. Some that lacked context got augmented. This iterative refinement based on testing produced better notes than trying to write them perfectly initially.

The metadata considerations influenced note organization. Notes are organized into directories by category (projects, skills, work, values, background, resources) which provides helpful organization for humans browsing the knowledge base but doesn't affect semantic search. The semantic search relies purely on content similarity - a query about leadership retrieves the leadership note whether it's in values, work, or skills directory. This separation of organizational structure from retrieval mechanism provides flexibility.

The LLM synthesis behavior guided writing decisions. Notes are written knowing an LLM will read them, not assuming human readers. This means being explicit about context rather than relying on implied information. It means including transitions and connections between points. It means providing specific details rather than referencing "as mentioned earlier" since there is no "earlier" when notes are retrieved independently. Writing for LLM synthesis produces different style than writing for human reading.

The avoiding overlap principle prevents notes from covering identical information. If two notes discuss similar topics, they approach from different angles. One note about WhatNow contextual bandits explains the algorithm. Another note about WhatNow technical challenges mentions contextual bandits among other challenges. This differentiation ensures retrieving multiple notes provides new information rather than repetition. The test-driven approach helps identify redundant notes that should be merged or refocused.

The update strategy maintains note accuracy as projects evolve. When Atlantis pivoted from underwater drone to surface boat, several notes needed updating or rewriting to reflect current architecture. Some old notes were preserved with context explaining the evolution. This historical perspective enriches the knowledge base - employers asking about pivots or adaptability get authentic examples from actual project history rather than sanitized success stories.

From a writing craft perspective, creating effective atomic notes requires balancing competing pressures: comprehensive yet focused, self-contained yet concise, conversational yet informative, redundant for context yet distinct for value. Finding this balance took practice and iteration. The early notes are adequate; later notes refined through experience are noticeably better. This quality improvement demonstrates learning and refinement rather than following rote formulas.

What I learned from developing the atomic notes philosophy is that writing for AI systems requires different instincts than writing for humans. Humans can ask clarifying questions if something is unclear. LLMs work with what you give them. Humans can reference earlier content in long documents. LLMs see only what's retrieved. Humans appreciate conciseness. LLMs benefit from redundant context. Understanding these differences produces better AI-ready content.

The atomic notes philosophy in Folio - focused scope, self-contained context, optimal sizing, first-person voice, natural language, synonym richness, concrete examples, deliberate redundancy, consistent structure, and writing for LLM synthesis - creates a knowledge base optimized for RAG system performance. This careful attention to content preparation distinguishes effective AI applications from brittle systems that technically work but generate poor results due to inadequate knowledge base design.

